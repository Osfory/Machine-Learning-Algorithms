{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd3eeb7-f2f7-4742-97ad-1696d10a6ffa",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms - Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c11c7f-5d8a-4d3c-bbbf-b31ec51ed3cd",
   "metadata": {},
   "source": [
    "## Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffc4146-23f4-44cc-9fe4-3a6856d74938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn.linear_model\n",
    "\n",
    "print(\"Imports Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1a06bb-5f5d-4d63-8a00-f04638fdc844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    random_seed = 42\n",
    "    train_size = 0.75\n",
    "\n",
    "print(Config.random_seed)\n",
    "print(Config.train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12fe03-9f6a-4945-883e-c51f322cc5be",
   "metadata": {},
   "source": [
    "## Regression - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8251847b-5766-408e-b335-57218ae57a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes(as_frame=True)\n",
    "X, y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa020d2c-c1a6-487a-a542-a57a9e75c529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  \n",
       "0   -0.002592  0.019907 -0.017646  \n",
       "1   -0.039493 -0.068332 -0.092204  \n",
       "2   -0.002592  0.002861 -0.025930  \n",
       "3    0.034309  0.022688 -0.009362  \n",
       "4   -0.002592 -0.031988 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "437 -0.002592  0.031193  0.007207  \n",
       "438  0.034309 -0.018114  0.044485  \n",
       "439 -0.011080 -0.046883  0.015491  \n",
       "440  0.026560  0.044529 -0.025930  \n",
       "441 -0.039493 -0.004222  0.003064  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf39d72-449a-4bd9-8c57-d84413c2222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLineReg:\n",
    "\n",
    "    def __init__(self, sgd_sample=None, metric=None, reg=None, l1_coef=0, l2_coef=0, random_state=42, n_iter=100, learning_rate=0.1):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = []\n",
    "        self.metric = metric\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.sgd_sample = sgd_sample\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MyLineReg class: n_iter={n_iter}, learning_rate={learning_rate}'\n",
    "\n",
    "    def compute_loss(self, weights, y, y_pred, reg, l1_coef, l2_coef):\n",
    "        loss = np.mean((y - y_pred)**2)\n",
    "        if reg == \"l1\":\n",
    "            return loss + l1_coef * np.sum(abs(weights))\n",
    "        elif reg == \"l2\":\n",
    "            return loss + l2_coef * np.sum(weights**2)\n",
    "        elif reg == \"elasticnet\":\n",
    "            return loss + l1_coef * np.sum(abs(weights)) + l2_coef * np.sum(weights**2)\n",
    "        return loss\n",
    "\n",
    "    def compute_weights(self, weights, learning_rate, X, y, y_pred, n_samples, num_iter, reg, l1_coef, l2_coef):\n",
    "        if callable(self.learning_rate):\n",
    "            if reg == None:\n",
    "                return weights - learning_rate(num_iter) * (2 / n_samples) * np.dot(X.T, y_pred - y)\n",
    "            elif reg == \"l1\":\n",
    "                return weights - learning_rate(num_iter) * ((2 / n_samples) * np.dot(X.T, y_pred - y) + l1_coef * np.sign(weights))\n",
    "            elif reg == \"l2\":\n",
    "                return weights - learning_rate(num_iter) * ((2 / n_samples) * np.dot(X.T, y_pred - y) + l2_coef * 2 * weights)\n",
    "            elif reg == \"elasticnet\":\n",
    "                return weights - learning_rate(num_iter) * ((2 / n_samples) * np.dot(X.T, y_pred - y) + l1_coef * np.sign(weights) + l2_coef * 2 * weights)\n",
    "        else:\n",
    "            if reg == None:\n",
    "                return weights - learning_rate * (2 / n_samples) * np.dot(X.T, y_pred - y)\n",
    "            elif reg == \"l1\":\n",
    "                return weights - learning_rate * ((2 / n_samples) * np.dot(X.T, y_pred - y) + l1_coef * np.sign(weights))\n",
    "            elif reg == \"l2\":\n",
    "                return weights - learning_rate * ((2 / n_samples) * np.dot(X.T, y_pred - y) + l2_coef * 2 * weights)\n",
    "            elif reg == \"elasticnet\":\n",
    "                return weights - learning_rate * ((2 / n_samples) * np.dot(X.T, y_pred - y) + l1_coef * np.sign(weights) + l2_coef * 2 * weights)\n",
    "    \n",
    "    def compute_metric(self, metric_name, y, y_pred):\n",
    "        if metric_name == None:\n",
    "            pass\n",
    "        elif metric_name == \"mse\":\n",
    "            return np.mean((y - y_pred)**2)\n",
    "        elif metric_name == \"mae\":\n",
    "            return np.mean(abs(y - y_pred))\n",
    "        elif metric_name == \"rmse\":\n",
    "            return np.sqrt(np.mean((y - y_pred)**2))\n",
    "        elif metric_name == \"mape\":\n",
    "            return 100 * np.mean(abs((y - y_pred) / y))\n",
    "        elif metric_name == \"r2\": \n",
    "            return 1 - np.mean((y - y_pred)**2)/np.mean((y - np.mean(y))**2)\n",
    "\n",
    "    def get_coef(self):\n",
    "        return self.weights[1:]\n",
    "        \n",
    "    def get_best_score(self):\n",
    "        return self.compute_metric(self.metric, y, np.dot(np.hstack((np.ones((X.shape[0], 1)), X)), self.weights))\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        return np.dot(X, self.weights)\n",
    "\n",
    "    def fit(self, X, y, verbose=False):\n",
    "        n_samples, n_features = X.shape\n",
    "        X = np.hstack((np.ones((n_samples, 1)), X))\n",
    "        self.weights = np.ones(n_features + 1)    \n",
    "\n",
    "        random.seed(self.random_state)\n",
    "     \n",
    "        for num_iter in range(1, self.n_iter + 1):\n",
    "\n",
    "            if isinstance(self.sgd_sample, int):\n",
    "                batch_size = self.sgd_sample\n",
    "            elif isinstance(self.sgd_sample, float):\n",
    "                batch_size = int(n_samples * self.sgd_sample)\n",
    "            else:\n",
    "                batch_size = n_samples\n",
    "                \n",
    "            sample_rows_idx = random.sample(range(X.shape[0]), batch_size)\n",
    "                \n",
    "            y_pred = np.dot(X, self.weights)\n",
    "            loss = self.compute_loss(self.weights, y, y_pred, self.reg, self.l1_coef, self.l2_coef)\n",
    "            self.weights = self.compute_weights(self.weights, self.learning_rate, X[sample_rows_idx], y.iloc[sample_rows_idx], y_pred[sample_rows_idx], batch_size, num_iter, self.reg, self.l1_coef, self.l2_coef)\n",
    "                    \n",
    "            if verbose and self.metric:\n",
    "                if num_iter == 1:\n",
    "                    print(f\"start | loss: {loss} | {self.metric}: {self.compute_metric(self.metric, y, y_pred)}\")\n",
    "                if num_iter % verbose == 0:\n",
    "                    print(f\"{self.n_iter} | loss: {loss} | {self.metric}: {self.compute_metric(self.metric, y, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39ee4964-c7e7-4ab5-82ea-e7910496b911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.56526458,   1.54787402,  41.77485153,  30.25568854,\n",
       "        14.34384202,  11.95453304, -26.43872364,  30.17356937,\n",
       "        39.85424619,  25.47414328])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_linreg_model_test = MyLineReg(sgd_sample=0.1)\n",
    "my_linreg_model_test.fit(X, y, verbose=100)\n",
    "my_linreg_model_test.get_coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0769af-eb99-4550-add2-e666e21d4e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start | loss: 28752.020614660887 | mae: 151.13348416289594\n",
      "100 | loss: 5700.346616390239 | mae: 64.52760766167967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.75147554,  1.78183055, 12.93809891,  9.95537628,  5.19244181,\n",
       "        4.40902338, -7.00724769,  9.6628404 , 12.47804144,  8.71161724])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_linreg_model = MyLineReg(metric=\"mae\", learning_rate=lambda iter: 0.5 * (0.85 ** iter))\n",
    "my_linreg_model.fit(X, y, verbose=100)\n",
    "my_linreg_model.get_coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2ef39e8-8110-465f-87f7-bff8394eca48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5177467808833367"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_linreg_model_2 = MyLineReg(metric=\"r2\", n_iter=10**5, learning_rate=0.999)\n",
    "my_linreg_model_2.fit(X, y)\n",
    "my_linreg_model_2.get_best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06f75c67-d2b2-4ee5-ac3c-73b1f055bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92aae154-8b9f-43e5-a072-33d785ede916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5177484222203499"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X, y)\n",
    "\n",
    "model_lr.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0185285e-4663-4d39-ab18-3f1432103b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6413370131918015e-06"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_linreg_model_2.get_best_score() - model_lr.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde22921-ca7b-4c55-9ce9-98db5bc9cc1d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2bd656-0ecc-43e9-a2b3-e168045bff9b",
   "metadata": {},
   "source": [
    "Красивый код от коллеги, надо посмотреть и научиться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af0088-b5d3-4e22-8833-039f7c3e4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyLineReg:\n",
    "#     def __init__(self, n_iter: int = 100, learning_rate: float = 0.1, metric: str = None) -> None:\n",
    "#         self.n_iter = n_iter\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self._weights = None\n",
    "#         self.metric = metric\n",
    "\n",
    "#     def __str__(self) -> str:\n",
    "#         params = [f'{key}={value}' for key, value in self.__dict__.items()]\n",
    "#         return 'MyLineReg class: ' + ', '.join(params)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _mae(y_true: np.array, y_pred: np.array):\n",
    "#         return (y_true - y_pred).abs().mean()\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _mse(y_true: np.array, y_pred: np.array):\n",
    "#         return (y_true - y_pred).pow(2).mean()\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _rmse(y_true: np.array, y_pred: np.array):\n",
    "#         return np.sqrt((y_true - y_pred).pow(2).mean())\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _mape(y_true: np.array, y_pred: np.array):\n",
    "#         return 100 * ((y_true - y_pred) / y_true).abs().mean()\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _r2(y_true: np.array, y_pred: np.array):\n",
    "#         return 1 - (y_true - y_pred).pow(2).sum() / ((y_true - y_true.mean()).pow(2).sum())\n",
    "\n",
    "#     def get_best_score(self):\n",
    "#         return self.score\n",
    "\n",
    "#     def fit(self, x: pd.DataFrame, y: pd.Series, verbose: int) -> None:\n",
    "#         x = pd.concat([pd.Series([1] * x.shape[0], index=x.index), x], axis=1).values\n",
    "#         self._weights = pd.Series([1.] * x.shape[1]).values\n",
    "#         for i in range(self.n_iter):\n",
    "#             y_hat = self._weights @ x.T\n",
    "#             mse = (y_hat - y).pow(2).mean()\n",
    "#             grad = (2 / y.shape[0]) * (y_hat - y) @ x\n",
    "#             self._weights -= self.learning_rate * grad\n",
    "#             if self.metric:\n",
    "#                 self.score = getattr(self, '_' + self.metric)(y, x @ self._weights)\n",
    "#             if verbose and i % verbose == 0:\n",
    "#                 if self.metric:\n",
    "#                     print(f'{i} | loss: {mse} | {self.metric}: {self.score}')\n",
    "#                 else:\n",
    "#                     print(f'{i} | loss: {mse}')\n",
    "\n",
    "#     def get_coef(self):\n",
    "#         return self._weights[1:]\n",
    "\n",
    "#     def predict(self, x: pd.DataFrame):\n",
    "#         x = pd.concat([pd.Series([1] * x.shape[0], index=x.index), x], axis=1).values\n",
    "#         return x @ self._weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f17bff-5622-4e7d-99b4-a789897d895b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b30f53a-1fe3-46c9-8a5b-0aad5e0c61e6",
   "metadata": {},
   "source": [
    "## Classification - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1870a61d-0227-4696-8b35-c4f045a6d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=14, n_informative=10, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'col_{col}' for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d44ae4b7-909f-41bb-b13e-3fa5a2d2ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogReg:\n",
    "\n",
    "    def __init__(self, metric=None, n_iter=10, learning_rate=0.1, eps=1e-15, reg=None, l1_coef=0, l2_coef=0, sgd_sample=None, random_state=42):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.eps = eps\n",
    "        self.weights = None\n",
    "        self.metric = metric\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.sgd_sample = sgd_sample\n",
    "        self.random_state = random_state        \n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}'\n",
    "    \n",
    "    def compute_loss(self, weights, y, y_pred, reg, l1_coef, l2_coef):\n",
    "        loss_result = -1 * np.mean(y * np.log(y_pred + self.eps) + (1 - y) * np.log(1 - y_pred + self.eps))\n",
    "        if reg == None:\n",
    "            return loss_result\n",
    "        elif reg == \"l1\":\n",
    "            return loss_result + l1_coef * np.sum(abs(weights))\n",
    "        elif reg == \"l2\":\n",
    "            return loss_result + l2_coef * np.sum(weights**2)\n",
    "        elif reg == \"elasticnet\":\n",
    "            return loss_result + l1_coef * np.sum(abs(weights)) + l2_coef * np.sum(weights**2)\n",
    "\n",
    "    def compute_weights(self, weights, learning_rate, X, y, y_pred, n_samples, num_iter, reg, l1_coef, l2_coef):\n",
    "        gradient = (1 / n_samples) * np.dot(X.T, y_pred - y)\n",
    "        if callable(learning_rate):\n",
    "            if reg == None:\n",
    "                return weights - learning_rate(num_iter) * gradient\n",
    "            elif reg == \"l1\":\n",
    "                return weights - learning_rate(num_iter) * (gradient + l1_coef * np.sign(weights))\n",
    "            elif reg == \"l2\":\n",
    "                return weights - learning_rate(num_iter) * (gradient + l2_coef * 2 * weights)\n",
    "            elif reg == \"elasticnet\":\n",
    "                return weights - learning_rate(num_iter) * (gradient + l1_coef * np.sign(weights) + l2_coef * 2 * weights)\n",
    "        else:\n",
    "            if reg == None:\n",
    "                return weights - learning_rate * gradient\n",
    "            elif reg == \"l1\":\n",
    "                return weights - learning_rate * (gradient + l1_coef * np.sign(weights))\n",
    "            elif reg == \"l2\":\n",
    "                return weights - learning_rate * (gradient + l2_coef * 2 * weights)\n",
    "            elif reg == \"elasticnet\":\n",
    "                return weights - learning_rate * (gradient + l1_coef * np.sign(weights) + l2_coef * 2 * weights)\n",
    "\n",
    "    def compute_metric(self, metric_name, y, y_pred, y_pred_proba):\n",
    "        item_index = np.where(y_pred == 1)\n",
    "        precision = np.sum(y.loc[item_index] == 1) / len(item_index[0])\n",
    "        recall = np.sum(y.loc[item_index] == 1) / np.sum(y)\n",
    "        \n",
    "        if metric_name == None:\n",
    "            pass\n",
    "        elif metric_name == \"accuracy\":\n",
    "            return np.sum(y == y_pred) / y.shape[0]\n",
    "        elif metric_name == \"precision\":\n",
    "            return precision\n",
    "        elif metric_name == \"recall\":\n",
    "            return recall\n",
    "        elif metric_name == \"f1\":\n",
    "            return (2 * precision * recall) / (precision + recall)\n",
    "        elif metric_name == \"roc_auc\": \n",
    "            labeled_probs = pd.DataFrame(data=np.array([y_pred_proba, y]).T, columns=[\"probability\", \"label\"])\n",
    "            labeled_probs = labeled_probs.sort_values(by=[\"probability\"], ascending=False)\n",
    "            labeled_probs[\"is_duplicated\"] = labeled_probs[\"probability\"].duplicated(keep=False)        \n",
    "            labeled_probs.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            result = 0\n",
    "            pos_counter = 0\n",
    "            \n",
    "            for index, row in labeled_probs.iterrows():\n",
    "                duplicated_labels = 0\n",
    "                \n",
    "                if row.label:\n",
    "                    pos_counter += 1\n",
    "                else:\n",
    "                    if row.is_duplicated:\n",
    "                        for sub_index, sub_row in labeled_probs.iterrows():\n",
    "                            if sub_row.probability == row.probability:\n",
    "                                duplicated_labels += 1\n",
    "                                if sub_index >= index:\n",
    "                                    result += pos_counter + duplicated_labels * 0.5\n",
    "                                    break\n",
    "                                else:\n",
    "                                    result += (pos_counter - 1) + duplicated_labels * 0.5\n",
    "                                    break\n",
    "                    else:\n",
    "                        result += pos_counter\n",
    "            roc_auc = result / (np.sum(y) * (len(y) - np.sum(y)))\n",
    "            return roc_auc\n",
    "\n",
    "    def get_best_score(self):\n",
    "        return self.compute_metric(self.metric, y, np.where((1 / (1 + np.exp(-1*np.dot(np.hstack((np.ones((X.shape[0], 1)), X)), self.weights)))) > 0.5, 1, 0), 1 / (1 + np.exp(-1*np.dot(np.hstack((np.ones((X.shape[0], 1)), X)), self.weights))))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X) > 0.5\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        return 1 / (1 + np.exp(-1*np.dot(X, self.weights)))\n",
    "                                       \n",
    "    def get_coef(self):\n",
    "        return self.weights[1:]\n",
    "\n",
    "    def fit(self, X, y, verbose=False):\n",
    "        n_samples, n_features = X.shape\n",
    "        X = np.hstack((np.ones((n_samples, 1)), X))\n",
    "        self.weights = np.ones(n_features + 1)\n",
    "\n",
    "        random.seed(self.random_state)\n",
    "        \n",
    "        for num_iter in range(1, self.n_iter + 1):\n",
    "\n",
    "            if isinstance(self.sgd_sample, int):\n",
    "                batch_size = self.sgd_sample\n",
    "            elif isinstance(self.sgd_sample, float):\n",
    "                batch_size = int(n_samples * self.sgd_sample)\n",
    "            else:\n",
    "                batch_size = n_samples\n",
    "                \n",
    "            sample_rows_idx = random.sample(range(X.shape[0]), batch_size)\n",
    "            \n",
    "            y_pred = 1 / (1 + np.exp(-1*np.dot(X, self.weights)))\n",
    "            loss = self.compute_loss(self.weights, y, y_pred, self.reg, self.l1_coef, self.l2_coef)\n",
    "            self.weights = self.compute_weights(self.weights, self.learning_rate, X[sample_rows_idx], y.iloc[sample_rows_idx], y_pred[sample_rows_idx], batch_size, num_iter, self.reg, self.l1_coef, self.l2_coef)\n",
    "           \n",
    "            if verbose and self.metric:\n",
    "                if num_iter == 1:\n",
    "                    print(f\"start | loss: {loss} | {self.metric}: {self.compute_metric(self.metric, y, np.where(y_pred > 0.5, 1, 0), y_pred)}\")\n",
    "                if num_iter % verbose == 0:\n",
    "                    print(f\"{self.n_iter} | loss: {loss} | {self.metric}: {self.compute_metric(self.metric, y, np.where(y_pred > 0.5, 1, 0), y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54014cb8-f0ae-4244-98fc-813ca2f8aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_logreg_model = MyLogReg()\n",
    "my_logreg_model.fit(X, y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "955a0380-db59-48f1-a4ac-2bb0bbfa37d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start | loss: 3.6736886876615524 | roc_auc: 0.5326141304565218\n",
      "100 | loss: 1.8729518266222966 | roc_auc: 0.6106664426657706\n",
      "100 | loss: 1.1626945313705064 | roc_auc: 0.7198908795635183\n",
      "100 | loss: 0.8288847284427477 | roc_auc: 0.7991111964447858\n",
      "100 | loss: 0.6548845902226954 | roc_auc: 0.8443873775495102\n",
      "100 | loss: 0.5606818660628208 | roc_auc: 0.8702874811499246\n",
      "100 | loss: 0.5054955690290941 | roc_auc: 0.8853355413421654\n",
      "100 | loss: 0.4701354545266514 | roc_auc: 0.8947515790063161\n",
      "100 | loss: 0.4456357293312561 | roc_auc: 0.9010436041744166\n",
      "100 | loss: 0.42761214161843997 | roc_auc: 0.9054516218064872\n",
      "100 | loss: 0.41378040631663504 | roc_auc: 0.9086556346225385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9089076356305426"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_logreg_model_2 = MyLogReg(n_iter=100, learning_rate=0.1, metric=\"roc_auc\")\n",
    "my_logreg_model_2.fit(X, y, verbose=10)\n",
    "my_logreg_model_2.get_best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02df1ee7-7f15-4ad4-a806-227cd36f4971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.0\n",
      "0.6071428571428571\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = [0.91, 0.86, 0.78, 0.6, 0.6, 0.55, 0.51, 0.46, 0.45, 0.45, 0.42]\n",
    "y_pred = [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]\n",
    "\n",
    "labeled_probs = pd.DataFrame(data=np.array([y_pred_proba, y_pred]).T, columns=[\"probability\", \"label\"])\n",
    "labeled_probs = labeled_probs.sort_values(by=[\"probability\"], ascending=False)\n",
    "labeled_probs[\"is_duplicated\"] = labeled_probs[\"probability\"].duplicated(keep=False)        \n",
    "labeled_probs.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "# print(labeled_probs)\n",
    "\n",
    "result = 0\n",
    "pos_counter = 0\n",
    "            \n",
    "for index, row in labeled_probs.iterrows():\n",
    "    duplicated_labels = 0\n",
    "                \n",
    "    if row.label:\n",
    "        pos_counter += 1\n",
    "    else:\n",
    "        if row.is_duplicated:\n",
    "            for sub_index, sub_row in labeled_probs.iterrows():\n",
    "                if sub_row.probability == row.probability:\n",
    "                    duplicated_labels += 1\n",
    "                    if sub_index >= index:\n",
    "                        result += pos_counter + duplicated_labels * 0.5\n",
    "                        break\n",
    "                    else:\n",
    "                        result += (pos_counter - 1) + duplicated_labels * 0.5\n",
    "                        break\n",
    "        else:\n",
    "            result += pos_counter\n",
    "\n",
    "print(result)\n",
    "print(result / (np.sum(y_pred) * (len(y_pred) - np.sum(y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba149e48-2328-4e2f-bcb5-5daebcf43b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab50e820-00de-4405-a528-04eefc38086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a019e5e7-a2fb-4d2b-b520-78c80603bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logreg = LogisticRegression()\n",
    "model_logreg.fit(X, y)\n",
    "\n",
    "model_logreg.score(X, y)\n",
    "y_pred = model_logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ec013cd-aa55-4d15-a3b8-289b6ccc3ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8519714078856315"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f51e3a-caaf-4f26-a46f-dadb7353a760",
   "metadata": {},
   "source": [
    "### Classification - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f3351-069d-4a09-8be8-0cbdbb722563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=14, n_informative=10, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'col_{col}' for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee7267ac-925c-4c75-9aa0-2ac328a78468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySVM:\n",
    "\n",
    "    def __init__(self, n_iter=10, learning_rate=0.001, weights=None, b=None, C=1):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = weights\n",
    "        self.b = b\n",
    "        self.C = C\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MySVM class: n_iter={self.n_iter}, learning_rate={self.learning_rate}'\n",
    "\n",
    "    def get_coef(self):\n",
    "        return (self.weights.tolist(), self.b)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.sign(np.dot(self.weights, X.T) + self.b)\n",
    "        y_pred[y_pred == -1] = 0\n",
    "        return y_pred.astype(int)\n",
    "    \n",
    "    def fit(self, X, y, verbose=False):\n",
    "        y = y.replace({0: -1})\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.ones(n_features)\n",
    "        self.b = 1\n",
    "\n",
    "        for num_iter in range(1, self.n_iter + 1):\n",
    "            for index, row in X.iterrows(): \n",
    "                if y[index] * (np.dot(self.weights, row) + self.b) >= 1:\n",
    "                    grad_weights = 2 * self.weights\n",
    "                    grad_b = 0\n",
    "                else:\n",
    "                    grad_weights = 2 * self.weights - self.C * y[index] * row\n",
    "                    grad_b = - self.C * y[index]\n",
    "                    \n",
    "                self.weights -= self.learning_rate * grad_weights\n",
    "                self.b -= self.learning_rate * grad_b\n",
    "    \n",
    "                svm_loss = np.linalg.norm(self.weights)**2 + self.C * (1 / n_samples) * np.sum(np.max([0, 1 - y[index] * (np.dot(self.weights, row) + self.b)]))\n",
    "            \n",
    "            if verbose:\n",
    "                if num_iter == 1:\n",
    "                    print(f\"start | loss: {svm_loss}\")\n",
    "                if num_iter % verbose == 0:\n",
    "                    print(f\"{self.n_iter} | loss: {svm_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "478c76cf-abbc-48b1-87b1-f604fa349da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.04494599106455738,\n",
       "  -0.01483486164366413,\n",
       "  0.09182867142612355,\n",
       "  -0.07651575744023459,\n",
       "  -0.2266593240042232,\n",
       "  0.05915742350197085,\n",
       "  -0.10037344311770476,\n",
       "  0.041232619182610106,\n",
       "  0.09646053125696591,\n",
       "  -0.0009606829156346712,\n",
       "  0.10519204525333291,\n",
       "  -0.010278356360164517,\n",
       "  -0.02125913100479772,\n",
       "  0.15067818851466888],\n",
       " 0.01999999999999902)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_svm_model = MySVM()\n",
    "my_svm_model.fit(X, y)\n",
    "my_svm_model.predict(X)\n",
    "my_svm_model.get_coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6979e7-f9fa-4e7a-845e-3087055dd8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541794a5-1d45-4322-933a-be7d32f03a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
